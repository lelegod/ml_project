{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f6ef9fd",
   "metadata": {},
   "source": [
    "Our prediction target for the regression is the mass attribute, as we stated it in our previous report. The mass will be predicted based on the following attributes: distance, stellar_magnitude, orbital_radius, orbital_period, eccentricity and radius attributes. This choice is based on our previous analysis and research of the dataset where we found that the mass could potentially have a high importance in predicting the planet type which we predict for our classification task.\n",
    "Sources: \n",
    "- https://www.kaggle.com/code/suhanikulshrestha02/exoplanet-characterization-using-ml\n",
    "- https://www.kaggle.com/code/mikedelong/looking-for-earth-like-planets-with-scatter-plots\n",
    "\n",
    "Additionally, the mass attribute was found to be less correlated with other variables than most other attributes (e.g. orbital period and orbital radius) which makes it a more interesting target for our Neural Network regression.\n",
    "[Correlation Matrix relevant part could be added...]\n",
    "\n",
    "In order to make our data suitable for regression tasks, we needed to do a few transformations. First of all, the mass attribute was stored in 2 separate attributes: mass_wrt, and mass_multiplier. This way the mass was always stored relative to Earth or Jupiter in the original dataset. To unify this, we converted the masses to kg and created a single mass variable. The same process was repeated for the radius_multiplier and radius_wrt attributes.\n",
    "\n",
    "Some attributes were excluded, as their meaning is not clear for such a task: E.g. Even though detection_method is part of our attribute list, it is not aligned with our objective as it is not a planetary characteristic, more of an artifact of the observation and categorization. Because of this reason such variables were considered to be irrelevant for this task.\n",
    "\n",
    "After these preparatory steps we standardized the data. It is important to highlight here that for the regression task both our features and our target variable was standardized. This choice was based on the scale of our mass attribute, which due to being calculated in kg-s, moves around the range of 10^20. This can lead into anomalies during the training (calculations with such numbers could more easily lead into overflows).\n",
    "\n",
    "Another important point is that the training and validation data has been standardized separately. This is to make sure that no information from the validation set leaks into the training set, which could happen if we standardize the whole dataset beforehand. In such scenario the mean and the variance is calculated on the whole dataset too which includes the samples from the validation set. Thus the model would be able to access this information indirectly based on the new scale of the training data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We chose these attributes as they were also the main target of our analysis for the last assignment.\n",
    "\n",
    "For this we will use a basline model to evaluate if our approach is more insightful than simply predicting the mean of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "580ae55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00167c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4765, 13)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"data/cleaned_5250.csv\")\n",
    "missing_values_idx = dataset.isna().any(axis=1)\n",
    "clean_dataset = dataset[~missing_values_idx]\n",
    "clean_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "083e00bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_obeservation = 4000\n",
    "df = clean_dataset.iloc[range(num_obeservation)]\n",
    "full_df = df.copy()\n",
    "df = df.drop(\"name\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27bfdf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle dataset\n",
    "df = df.sample(frac=1, random_state=11).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5495a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      distance  stellar_magnitude   planet_type  discovery_year  \\\n",
      "0       1254.0           12.91800  Neptune-like            2014   \n",
      "1        915.0           13.84700  Neptune-like            2018   \n",
      "2         90.0            7.00000     Gas Giant            2022   \n",
      "3       3366.0           15.94400  Neptune-like            2014   \n",
      "4       9394.0           15.35100  Neptune-like            2016   \n",
      "...        ...                ...           ...             ...   \n",
      "3995    2040.0           13.27000   Super Earth            2014   \n",
      "3996    4358.0           16.01900  Neptune-like            2014   \n",
      "3997     240.0            8.01852     Gas Giant            2004   \n",
      "3998    5519.0           15.40400  Neptune-like            2016   \n",
      "3999    4850.0           14.19600   Super Earth            2016   \n",
      "\n",
      "      orbital_radius  orbital_period  eccentricity detection_method  \\\n",
      "0           0.110000        0.035866          0.00          Transit   \n",
      "1           0.049700        0.012047          0.00          Transit   \n",
      "2          13.125939       47.100000          0.07  Radial Velocity   \n",
      "3           0.104000        0.034771          0.00          Transit   \n",
      "4           0.193900        0.083504          0.00          Transit   \n",
      "...              ...             ...           ...              ...   \n",
      "3995        0.051000        0.010951          0.00          Transit   \n",
      "3996        0.090000        0.026557          0.00          Transit   \n",
      "3997        0.047900        0.009309          0.03  Radial Velocity   \n",
      "3998        0.165400        0.067077          0.00          Transit   \n",
      "3999        0.380000        0.182341          0.00          Transit   \n",
      "\n",
      "              mass     radius  \n",
      "0     3.577228e+25  14471.577  \n",
      "1     5.380772e+25  18386.593  \n",
      "2     1.104693e+28  79698.540  \n",
      "3     3.374180e+25  13982.200  \n",
      "4     3.045720e+25  13457.580  \n",
      "...            ...        ...  \n",
      "3995  1.182456e+25   7781.160  \n",
      "3996  3.069608e+25  13521.360  \n",
      "3997  1.935960e+27  85990.530  \n",
      "3998  7.285840e+25  21952.054  \n",
      "3999  2.484352e+25  11926.860  \n",
      "\n",
      "[4000 rows x 10 columns] (4000, 10)\n"
     ]
    }
   ],
   "source": [
    "# mass transformation: The dataset contains a mass calculation based on two planets. We unify that into a single mass variable\n",
    "jupiter_mass_kg = 1.898 * 10**27 #kg\n",
    "jupiter_radius_km = 69911 #km\n",
    "earth_mass_kg = 5.972 * 10**24\n",
    "earth_radius_km = 6378\n",
    "df[\"mass_wrt\"] = np.where(df[\"mass_wrt\"] == \"Jupiter\", jupiter_mass_kg, earth_mass_kg)\n",
    "df[\"mass\"] = np.multiply(df[\"mass_multiplier\"], df[\"mass_wrt\"])\n",
    "df[\"radius_wrt\"] = np.where(df[\"radius_wrt\"] == \"Jupiter\", jupiter_radius_km, earth_radius_km)\n",
    "df[\"radius\"] = np.multiply(df[\"radius_multiplier\"], df[\"radius_wrt\"])\n",
    "df = df.drop([\"mass_wrt\", \"radius_wrt\", \"mass_multiplier\", \"radius_multiplier\"], axis=1)\n",
    "print(df, df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2259b62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>stellar_magnitude</th>\n",
       "      <th>planet_type</th>\n",
       "      <th>discovery_year</th>\n",
       "      <th>orbital_radius</th>\n",
       "      <th>orbital_period</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>detection_method</th>\n",
       "      <th>mass</th>\n",
       "      <th>radius</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1254.0</td>\n",
       "      <td>12.91800</td>\n",
       "      <td>Neptune-like</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.035866</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Transit</td>\n",
       "      <td>3.577228e+25</td>\n",
       "      <td>14471.577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>915.0</td>\n",
       "      <td>13.84700</td>\n",
       "      <td>Neptune-like</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>0.012047</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Transit</td>\n",
       "      <td>5.380772e+25</td>\n",
       "      <td>18386.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.0</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>Gas Giant</td>\n",
       "      <td>2022</td>\n",
       "      <td>13.125939</td>\n",
       "      <td>47.100000</td>\n",
       "      <td>0.07</td>\n",
       "      <td>Radial Velocity</td>\n",
       "      <td>1.104693e+28</td>\n",
       "      <td>79698.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3366.0</td>\n",
       "      <td>15.94400</td>\n",
       "      <td>Neptune-like</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.034771</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Transit</td>\n",
       "      <td>3.374180e+25</td>\n",
       "      <td>13982.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9394.0</td>\n",
       "      <td>15.35100</td>\n",
       "      <td>Neptune-like</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.193900</td>\n",
       "      <td>0.083504</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Transit</td>\n",
       "      <td>3.045720e+25</td>\n",
       "      <td>13457.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>579.0</td>\n",
       "      <td>13.49900</td>\n",
       "      <td>Terrestrial</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.011225</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Transit</td>\n",
       "      <td>4.473028e+24</td>\n",
       "      <td>5931.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>133.0</td>\n",
       "      <td>6.68804</td>\n",
       "      <td>Gas Giant</td>\n",
       "      <td>2022</td>\n",
       "      <td>3.530000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>0.41</td>\n",
       "      <td>Direct Imaging</td>\n",
       "      <td>2.410460e+28</td>\n",
       "      <td>102070.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>405.0</td>\n",
       "      <td>16.40000</td>\n",
       "      <td>Neptune-like</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>0.059685</td>\n",
       "      <td>0.08</td>\n",
       "      <td>Transit</td>\n",
       "      <td>3.218908e+25</td>\n",
       "      <td>13904.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2875.0</td>\n",
       "      <td>13.25800</td>\n",
       "      <td>Super Earth</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.025188</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Transit</td>\n",
       "      <td>1.319812e+25</td>\n",
       "      <td>8227.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>3072.0</td>\n",
       "      <td>14.13200</td>\n",
       "      <td>Super Earth</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Transit</td>\n",
       "      <td>2.281304e+25</td>\n",
       "      <td>11352.840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     distance  stellar_magnitude   planet_type  discovery_year  \\\n",
       "0      1254.0           12.91800  Neptune-like            2014   \n",
       "1       915.0           13.84700  Neptune-like            2018   \n",
       "2        90.0            7.00000     Gas Giant            2022   \n",
       "3      3366.0           15.94400  Neptune-like            2014   \n",
       "4      9394.0           15.35100  Neptune-like            2016   \n",
       "..        ...                ...           ...             ...   \n",
       "995     579.0           13.49900   Terrestrial            2014   \n",
       "996     133.0            6.68804     Gas Giant            2022   \n",
       "997     405.0           16.40000  Neptune-like            2017   \n",
       "998    2875.0           13.25800   Super Earth            2014   \n",
       "999    3072.0           14.13200   Super Earth            2016   \n",
       "\n",
       "     orbital_radius  orbital_period  eccentricity detection_method  \\\n",
       "0          0.110000        0.035866          0.00          Transit   \n",
       "1          0.049700        0.012047          0.00          Transit   \n",
       "2         13.125939       47.100000          0.07  Radial Velocity   \n",
       "3          0.104000        0.034771          0.00          Transit   \n",
       "4          0.193900        0.083504          0.00          Transit   \n",
       "..              ...             ...           ...              ...   \n",
       "995        0.044000        0.011225          0.00          Transit   \n",
       "996        3.530000        5.700000          0.41   Direct Imaging   \n",
       "997        0.121000        0.059685          0.08          Transit   \n",
       "998        0.091000        0.025188          0.00          Transit   \n",
       "999        0.044400        0.009856          0.00          Transit   \n",
       "\n",
       "             mass      radius  \n",
       "0    3.577228e+25   14471.577  \n",
       "1    5.380772e+25   18386.593  \n",
       "2    1.104693e+28   79698.540  \n",
       "3    3.374180e+25   13982.200  \n",
       "4    3.045720e+25   13457.580  \n",
       "..            ...         ...  \n",
       "995  4.473028e+24    5931.540  \n",
       "996  2.410460e+28  102070.060  \n",
       "997  3.218908e+25   13904.040  \n",
       "998  1.319812e+25    8227.620  \n",
       "999  2.281304e+25   11352.840  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c84544e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance             1.0\n",
      "stellar_magnitude    1.0\n",
      "orbital_radius       1.0\n",
      "orbital_period       1.0\n",
      "eccentricity         1.0\n",
      "mass                 1.0\n",
      "radius               1.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>stellar_magnitude</th>\n",
       "      <th>orbital_radius</th>\n",
       "      <th>orbital_period</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>mass</th>\n",
       "      <th>radius</th>\n",
       "      <th>planet_type</th>\n",
       "      <th>detection_method</th>\n",
       "      <th>discovery_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.353356</td>\n",
       "      <td>0.076206</td>\n",
       "      <td>-0.038587</td>\n",
       "      <td>-0.020460</td>\n",
       "      <td>-0.472049</td>\n",
       "      <td>-0.107968</td>\n",
       "      <td>-0.549389</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.563231</td>\n",
       "      <td>0.369147</td>\n",
       "      <td>-0.039057</td>\n",
       "      <td>-0.020461</td>\n",
       "      <td>-0.472049</td>\n",
       "      <td>-0.107256</td>\n",
       "      <td>-0.425618</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.073990</td>\n",
       "      <td>-1.789910</td>\n",
       "      <td>0.062761</td>\n",
       "      <td>-0.017790</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.326747</td>\n",
       "      <td>1.512709</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.954187</td>\n",
       "      <td>1.030391</td>\n",
       "      <td>-0.038634</td>\n",
       "      <td>-0.020460</td>\n",
       "      <td>-0.472049</td>\n",
       "      <td>-0.108048</td>\n",
       "      <td>-0.564860</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.686132</td>\n",
       "      <td>0.843401</td>\n",
       "      <td>-0.037934</td>\n",
       "      <td>-0.020457</td>\n",
       "      <td>-0.472049</td>\n",
       "      <td>-0.108178</td>\n",
       "      <td>-0.581445</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>0.133258</td>\n",
       "      <td>0.187202</td>\n",
       "      <td>-0.039047</td>\n",
       "      <td>-0.020461</td>\n",
       "      <td>-0.472049</td>\n",
       "      <td>-0.108913</td>\n",
       "      <td>-0.760901</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>1.568336</td>\n",
       "      <td>1.054041</td>\n",
       "      <td>-0.038743</td>\n",
       "      <td>-0.020461</td>\n",
       "      <td>-0.472049</td>\n",
       "      <td>-0.108168</td>\n",
       "      <td>-0.579429</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>-0.981125</td>\n",
       "      <td>-1.468741</td>\n",
       "      <td>-0.039071</td>\n",
       "      <td>-0.020462</td>\n",
       "      <td>-0.269336</td>\n",
       "      <td>-0.032949</td>\n",
       "      <td>1.711625</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>2.287113</td>\n",
       "      <td>0.860114</td>\n",
       "      <td>-0.038156</td>\n",
       "      <td>-0.020458</td>\n",
       "      <td>-0.472049</td>\n",
       "      <td>-0.106504</td>\n",
       "      <td>-0.312899</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>1.872934</td>\n",
       "      <td>0.479196</td>\n",
       "      <td>-0.036485</td>\n",
       "      <td>-0.020452</td>\n",
       "      <td>-0.472049</td>\n",
       "      <td>-0.108399</td>\n",
       "      <td>-0.629838</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      distance  stellar_magnitude  orbital_radius  orbital_period  \\\n",
       "0    -0.353356           0.076206       -0.038587       -0.020460   \n",
       "1    -0.563231           0.369147       -0.039057       -0.020461   \n",
       "2    -1.073990          -1.789910        0.062761       -0.017790   \n",
       "3     0.954187           1.030391       -0.038634       -0.020460   \n",
       "4     4.686132           0.843401       -0.037934       -0.020457   \n",
       "...        ...                ...             ...             ...   \n",
       "3995  0.133258           0.187202       -0.039047       -0.020461   \n",
       "3996  1.568336           1.054041       -0.038743       -0.020461   \n",
       "3997 -0.981125          -1.468741       -0.039071       -0.020462   \n",
       "3998  2.287113           0.860114       -0.038156       -0.020458   \n",
       "3999  1.872934           0.479196       -0.036485       -0.020452   \n",
       "\n",
       "      eccentricity      mass    radius  planet_type  detection_method  \\\n",
       "0        -0.472049 -0.107968 -0.549389            1                 6   \n",
       "1        -0.472049 -0.107256 -0.425618            1                 6   \n",
       "2         0.000947  0.326747  1.512709            0                 5   \n",
       "3        -0.472049 -0.108048 -0.564860            1                 6   \n",
       "4        -0.472049 -0.108178 -0.581445            1                 6   \n",
       "...            ...       ...       ...          ...               ...   \n",
       "3995     -0.472049 -0.108913 -0.760901            2                 6   \n",
       "3996     -0.472049 -0.108168 -0.579429            1                 6   \n",
       "3997     -0.269336 -0.032949  1.711625            0                 5   \n",
       "3998     -0.472049 -0.106504 -0.312899            1                 6   \n",
       "3999     -0.472049 -0.108399 -0.629838            2                 6   \n",
       "\n",
       "      discovery_year  \n",
       "0                 18  \n",
       "1                 22  \n",
       "2                 26  \n",
       "3                 18  \n",
       "4                 20  \n",
       "...              ...  \n",
       "3995              18  \n",
       "3996              18  \n",
       "3997               8  \n",
       "3998              20  \n",
       "3999              20  \n",
       "\n",
       "[4000 rows x 10 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "planet_type = df[\"planet_type\"]\n",
    "encoded_df = df.copy()\n",
    "#we encode the categorical variables, to make it digestable for the training stage later\n",
    "encoded_df[\"detection_method\"] = encoded_df[\"detection_method\"].astype(\"category\").cat.codes\n",
    "encoded_df[\"planet_type\"] = encoded_df[\"planet_type\"].astype(\"category\").cat.codes\n",
    "encoded_df[\"discovery_year\"] = encoded_df[\"discovery_year\"].astype(\"category\").cat.codes\n",
    "\n",
    "#we have a separate df, so that the standardization is only done for the non-categorical variables\n",
    "df_without_type = encoded_df.drop([\"planet_type\", \"detection_method\", \"discovery_year\"] , axis=1)\n",
    "\n",
    "df_std = (df_without_type - np.mean(df_without_type, axis=0)) / np.std(df_without_type, axis=0)\n",
    "print(np.std(df_std, axis=0))\n",
    "\n",
    "#we add back everything\n",
    "df_std[\"planet_type\"] = encoded_df[\"planet_type\"]\n",
    "df_std[\"detection_method\"] = encoded_df[\"detection_method\"]\n",
    "df_std[\"discovery_year\"] = encoded_df[\"discovery_year\"]\n",
    "df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a06a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = df_without_type.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03301f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Gas Giant', 'Neptune-like', 'Super Earth', 'Terrestrial'], dtype='object')\n",
      "Index(['Astrometry', 'Direct Imaging', 'Disk Kinematics',\n",
      "       'Eclipse Timing Variations', 'Orbital Brightness Modulation',\n",
      "       'Radial Velocity', 'Transit', 'Transit Timing Variations'],\n",
      "      dtype='object')\n",
      "Index([1995, 1996, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007,\n",
      "       2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019,\n",
      "       2020, 2021, 2022, 2023],\n",
      "      dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "planet_cats = df[\"planet_type\"].astype(\"category\")\n",
    "print(planet_cats.cat.categories) \n",
    "detection_cats = df[\"detection_method\"].astype(\"category\")\n",
    "print(detection_cats.cat.categories)\n",
    "discovery_cats = df[\"discovery_year\"].astype(\"category\")\n",
    "print(discovery_cats.cat.categories) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b5e32cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 5) (4000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = df_train.drop(columns=['mass', 'orbital_period']).values\n",
    "X_columns = df_without_type.drop(columns=['mass']).columns\n",
    "y = df_train['mass'].values\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "X_train_full = X[:3000]\n",
    "X_test_full = X[3000:]\n",
    "y_train_full = y[:3000]\n",
    "y_test_full = y[3000:]\n",
    "X_test_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ad4c934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.57722800e+25, 5.38077200e+25, 1.10469294e+28, ...,\n",
       "       1.93596000e+27, 7.28584000e+25, 2.48435200e+25], shape=(4000,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6772d4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a2d8bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.logspace(-10, 1, 200)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=12)\n",
    "\n",
    "train_errors = []\n",
    "test_errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4330223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "for lam in lambdas:\n",
    "    fold_train_errors = []\n",
    "    fold_test_errors = []\n",
    "    \n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Manual scaling of X and y\n",
    "        X_mean = np.mean(X_train, axis=0)\n",
    "        X_std = np.std(X_train, axis=0)\n",
    "        X_train_scaled = (X_train - X_mean) / X_std\n",
    "        X_test_scaled = (X_test - X_mean) / X_std\n",
    "\n",
    "        y_mean = np.mean(y_train)\n",
    "        y_std = np.std(y_train)\n",
    "        y_train_scaled = (y_train - y_mean) / y_std\n",
    "        y_test_scaled = (y_test - y_mean) / y_std\n",
    "\n",
    "        ridge = Ridge(alpha=lam)\n",
    "        ridge.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "\n",
    "        # Predictions\n",
    "        y_pred_train = ridge.predict(X_train_scaled)\n",
    "        y_pred_test = ridge.predict(X_test_scaled)\n",
    "\n",
    "        fold_train_errors.append(mean_squared_error(y_train_scaled, y_pred_train))\n",
    "        fold_test_errors.append(mean_squared_error(y_test_scaled, y_pred_test))\n",
    "\n",
    "    train_errors.append(np.mean(fold_train_errors))\n",
    "    test_errors.append(np.mean(fold_test_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acaa7d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal lambda = 0.0000\n",
      "Minimum Cross-Validation error = 4.4272\n"
     ]
    }
   ],
   "source": [
    "#optimal lambda\n",
    "optimal_idx = np.argmin(test_errors)\n",
    "optimal_lambda = lambdas[optimal_idx]\n",
    "optimal_error = test_errors[optimal_idx]\n",
    "\n",
    "print(f\"Optimal lambda = {optimal_lambda:.4f}\")\n",
    "print(f\"Minimum Cross-Validation error = {optimal_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34ef27f",
   "metadata": {},
   "source": [
    "For the calculation of the generalization error K = 10 fold cross-validation was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f04453cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(lambdas, train_errors, marker='o', label='Training error')\n",
    "plt.plot(lambdas, test_errors, marker='s', label='Test error')\n",
    "\n",
    "# Highlight optimal lambda\n",
    "plt.axvline(optimal_lambda, color='red', linestyle='--', label=f'Optimal lambda = {optimal_lambda:.2f}')\n",
    "plt.scatter(optimal_lambda, optimal_error, color='red', s=80, zorder=5)\n",
    "\n",
    "# Labels and legend\n",
    "plt.xlabel('Regularization parameter lambda')\n",
    "plt.ylabel('Mean squared error (on standardized y)')\n",
    "plt.title('Generalization error vs. lambda (10-fold Cross-Validation)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03265403",
   "metadata": {},
   "source": [
    "As visible on the plot the linear regression model fails to capture the test data. There is a visible difference on the test and the training error. This indicates overfitting on the training set, as the model is not able to generalize the knowledge to the test set, this means that the parameters of the model are tuned to the data it was trained on. \n",
    "\n",
    "\n",
    "This is a logical result when we look deeper into the attributes: The mass is not in a linear relationship with the other attributes. As it is also stated in Kepler's laws (which can be used for planet mass estimation if there is a moon or a spacecraft in orbit of the planet): https://en.wikipedia.org/wiki/Kepler%27s_laws_of_planetary_motion the relationship between some of these attributes is already quadratic or third degree, additionally there is no clear equation that would describe the relationships between our input and target attributes.\n",
    "\n",
    "At the same time it is also observable that regularization helps with limiting the generalization error. As we increase lambda, the generalization error drops, then starts increasing while the training error steadily increases as we include higher and higher lambdas. This is a direct consequence of how regularization is applied, as it \"forces\" the weights away from the overfitting solution. However, if the lambda parameter is too high, it prevents the model from capturing the data and the regularization penalty won't enable the model to fit the data.\n",
    "[Formula for regularization]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d93b76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.32415271e-02,  1.19637820e-01,  4.52354500e-05, -1.04365631e-01,\n",
       "         4.79358643e-01]),\n",
       " np.float64(1.9005117198210288e-17),\n",
       " 0.8434489244980432,\n",
       " 0.21528307970735622)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(alpha=optimal_lambda)\n",
    "\n",
    "X_train_scaled = (X_train_full - np.mean(X_train_full, axis=0)) / np.std(X_train_full, axis=0)\n",
    "y_train_scaled = (y_train_full - np.mean(y_train_full)) / np.std(y_train_full)\n",
    "\n",
    "X_test_scaled = (X_test_full - np.mean(X_train_full, axis=0)) / np.std(X_train_full, axis=0)\n",
    "y_test_scaled = (y_test_full - np.mean(y_train_full)) / np.std(y_train_full)\n",
    "\n",
    "ridge.fit(X_train_scaled, y_train_scaled)\n",
    "coeffs = ridge.coef_\n",
    "intercept = ridge.intercept_\n",
    "\n",
    "y_pred_train = ridge.predict(X_train_scaled)\n",
    "y_pred_test = ridge.predict(X_test_scaled)\n",
    "\n",
    "train_error = mean_squared_error(y_train_scaled, y_pred_train)\n",
    "test_error = mean_squared_error(y_test_scaled, y_pred_test)\n",
    "\n",
    "coeffs, intercept, train_error, test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21d7ca76",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m coeffs = np.round(coeffs, \u001b[32m3\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# create a table from X_Columns and coeffs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m coeffs_table = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mFeature\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCoefficient\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoeffs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m coeffs_table\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\boton\\miniconda3\\envs\\dtucompvis\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    772\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    773\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    774\u001b[39m     )\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    777\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     mgr = \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\boton\\miniconda3\\envs\\dtucompvis\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    500\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    501\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\boton\\miniconda3\\envs\\dtucompvis\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         index = \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    116\u001b[39m         index = ensure_index(index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\boton\\miniconda3\\envs\\dtucompvis\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[39m, in \u001b[36m_extract_index\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    675\u001b[39m lengths = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[32m    676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAll arrays must be of the same length\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[32m    680\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    681\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    682\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "#round coefficients for better visibility\n",
    "coeffs = np.round(coeffs, 3)\n",
    "\n",
    "# create a table from X_Columns and coeffs\n",
    "coeffs_table = pd.DataFrame({'Feature': X_columns, 'Coefficient': coeffs})\n",
    "coeffs_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2e4d58",
   "metadata": {},
   "source": [
    "Linear regression aims to fit a linear combination of the input features to capture the output feature: f(x,w) = w0 +\n",
    "w1x1+· · ·+wMxM.\n",
    "Now we go deeper into our optimal linear model by looking at the coefficients. These show how the individual attributes are weighted in the linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037532ea",
   "metadata": {},
   "source": [
    "As we see the last coefficient is the most significant, which corresponds to the last attribute in our training data. This coefficient is for the radius. This is in line with our previous analysis from the correlation matrix which also showed the strongest correlation between these 2 attributes. The other 5 coefficients are signifcantly smaller which is again in sync with the observations from our data analysis.\n",
    "[correlation matrix comparison]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "76a32428",
   "metadata": {},
   "outputs": [],
   "source": [
    "K1 = 5  # outer folds\n",
    "K2 = 5  # inner folds\n",
    "\n",
    "# Regularization and ANN hyperparameters\n",
    "lambdas = np.logspace(-5, 5, 50)\n",
    "hidden_units = [1, 8, 16, 32, 64, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f78cda2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage\n",
    "test_errors_outer = {\n",
    "    'baseline': np.zeros(K1),\n",
    "    'ridge': np.zeros(K1),\n",
    "    'ann': np.zeros(K1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "61b09aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_hs = np.zeros(K1)\n",
    "optimal_lambdas = np.zeros(K1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "056f689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class PredictorANN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_units):\n",
    "        super(PredictorANN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "fa4a32ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepANN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_units):\n",
    "        super(DeepANN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "0faf85ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_custom_ann(X_train, y_train, X_val, y_val, hidden_units, \n",
    "                      lr=1e-3, weight_decay=0.0, epochs=200, batch_size=32, verbose=False):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    X_train_t = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train_t = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32).to(device)\n",
    "    X_val_t = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "    y_val_t = torch.tensor(y_val.reshape(-1, 1), dtype=torch.float32).to(device)\n",
    "\n",
    "    # Datasets and loaders\n",
    "    train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Initialize model, loss, optimizer\n",
    "    model = DeepANN(X_train.shape[1], hidden_units).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_preds = model(X_val_t)\n",
    "        val_loss = criterion(val_preds, y_val_t).item()\n",
    "\n",
    "    print(f'Validation Loss: {val_loss}')\n",
    "    return val_loss, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1636794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.2783637046813965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6.2783637046813965,\n",
       " PredictorANN(\n",
       "   (model): Sequential(\n",
       "     (0): Linear(in_features=6, out_features=32, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_custom_ann(X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled, hidden_units=32, lr=1e-10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "81315fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer fold 1/5\n",
      "hidden unit: 1\n",
      "Validation Loss: 0.44315454363822937\n",
      "Validation Loss: 1.1709097623825073\n",
      "Validation Loss: 0.12866638600826263\n",
      "Validation Loss: 4.324999809265137\n",
      "Validation Loss: 0.5289130210876465\n",
      "hidden unit: 8\n",
      "Validation Loss: 4.216815948486328\n",
      "Validation Loss: 0.16830909252166748\n",
      "Validation Loss: 0.25400739908218384\n",
      "Validation Loss: 0.41138631105422974\n",
      "Validation Loss: 0.08739017695188522\n",
      "hidden unit: 16\n",
      "Validation Loss: 0.23609042167663574\n",
      "Validation Loss: 0.22144556045532227\n",
      "Validation Loss: 0.297905832529068\n",
      "Validation Loss: 4.23317289352417\n",
      "Validation Loss: 0.16664545238018036\n",
      "hidden unit: 32\n",
      "Validation Loss: 4.307493686676025\n",
      "Validation Loss: 0.034842170774936676\n",
      "Validation Loss: 0.3363153040409088\n",
      "Validation Loss: 0.1750825196504593\n",
      "Validation Loss: 0.26608070731163025\n",
      "hidden unit: 64\n",
      "Validation Loss: 0.21275679767131805\n",
      "Validation Loss: 0.05338643863797188\n",
      "Validation Loss: 0.3450445830821991\n",
      "Validation Loss: 4.259563446044922\n",
      "Validation Loss: 0.13509677350521088\n",
      "hidden unit: 128\n",
      "Validation Loss: 0.19402912259101868\n",
      "Validation Loss: 4.495052814483643\n",
      "Validation Loss: 0.14330768585205078\n",
      "Validation Loss: 0.04929133132100105\n",
      "Validation Loss: 0.18338508903980255\n",
      "Validation Loss: 0.06564447283744812\n",
      "ANN test error: 0.06564447262969576\n",
      "Outer fold 2/5\n",
      "hidden unit: 1\n",
      "Validation Loss: 0.8986971974372864\n",
      "Validation Loss: 0.5992042422294617\n",
      "Validation Loss: 1.524834394454956\n",
      "Validation Loss: 2.0977399349212646\n",
      "Validation Loss: 1.1613155603408813\n",
      "hidden unit: 8\n",
      "Validation Loss: 0.34928083419799805\n",
      "Validation Loss: 1.6511372327804565\n",
      "Validation Loss: 0.3768984079360962\n",
      "Validation Loss: 1.7591503858566284\n",
      "Validation Loss: 1.319353461265564\n",
      "hidden unit: 16\n",
      "Validation Loss: 0.3677271902561188\n",
      "Validation Loss: 0.8820319175720215\n",
      "Validation Loss: 1.2354024648666382\n",
      "Validation Loss: 0.4094918370246887\n",
      "Validation Loss: 2.1511969566345215\n",
      "hidden unit: 32\n",
      "Validation Loss: 1.0550512075424194\n",
      "Validation Loss: 0.34625133872032166\n",
      "Validation Loss: 1.525715708732605\n",
      "Validation Loss: 0.9448769688606262\n",
      "Validation Loss: 1.1738178730010986\n",
      "hidden unit: 64\n",
      "Validation Loss: 2.246715545654297\n",
      "Validation Loss: 0.2735944092273712\n",
      "Validation Loss: 0.4030837118625641\n",
      "Validation Loss: 1.7420810461044312\n",
      "Validation Loss: 0.326249897480011\n",
      "hidden unit: 128\n",
      "Validation Loss: 0.24414105713367462\n",
      "Validation Loss: 0.32846057415008545\n",
      "Validation Loss: 1.8865059614181519\n",
      "Validation Loss: 0.30889925360679626\n",
      "Validation Loss: 2.2285611629486084\n",
      "Validation Loss: 24.601274490356445\n",
      "ANN test error: 24.601270240588736\n",
      "Outer fold 3/5\n",
      "hidden unit: 1\n",
      "Validation Loss: 4.396633625030518\n",
      "Validation Loss: 0.9444628953933716\n",
      "Validation Loss: 0.14621904492378235\n",
      "Validation Loss: 0.4168473184108734\n",
      "Validation Loss: 1.0798157453536987\n",
      "hidden unit: 8\n",
      "Validation Loss: 0.041187722235918045\n",
      "Validation Loss: 0.16802111268043518\n",
      "Validation Loss: 0.23404920101165771\n",
      "Validation Loss: 0.30303797125816345\n",
      "Validation Loss: 4.516604900360107\n",
      "hidden unit: 16\n",
      "Validation Loss: 0.10103287547826767\n",
      "Validation Loss: 0.24105258285999298\n",
      "Validation Loss: 0.3187558650970459\n",
      "Validation Loss: 4.491049289703369\n",
      "Validation Loss: 0.05051420256495476\n",
      "hidden unit: 32\n",
      "Validation Loss: 0.18361929059028625\n",
      "Validation Loss: 4.318449020385742\n",
      "Validation Loss: 0.0816914439201355\n",
      "Validation Loss: 0.07398230582475662\n",
      "Validation Loss: 0.3674255311489105\n",
      "hidden unit: 64\n",
      "Validation Loss: 0.16235440969467163\n",
      "Validation Loss: 0.16513437032699585\n",
      "Validation Loss: 0.17769627273082733\n",
      "Validation Loss: 0.1498972475528717\n",
      "Validation Loss: 4.361555576324463\n",
      "hidden unit: 128\n",
      "Validation Loss: 0.18730317056179047\n",
      "Validation Loss: 4.401310443878174\n",
      "Validation Loss: 0.04340745136141777\n",
      "Validation Loss: 0.14570216834545135\n",
      "Validation Loss: 0.24252668023109436\n",
      "Validation Loss: 0.7648003101348877\n",
      "ANN test error: 0.7648003882242775\n",
      "Outer fold 4/5\n",
      "hidden unit: 1\n",
      "Validation Loss: 0.200602725148201\n",
      "Validation Loss: 4.784394264221191\n",
      "Validation Loss: 0.4110165536403656\n",
      "Validation Loss: 0.08944431692361832\n",
      "Validation Loss: 0.38153308629989624\n",
      "hidden unit: 8\n",
      "Validation Loss: 4.219871520996094\n",
      "Validation Loss: 0.175637349486351\n",
      "Validation Loss: 0.35327407717704773\n",
      "Validation Loss: 0.11875715106725693\n",
      "Validation Loss: 0.1989334374666214\n",
      "hidden unit: 16\n",
      "Validation Loss: 0.3416694700717926\n",
      "Validation Loss: 0.15060190856456757\n",
      "Validation Loss: 4.16378927230835\n",
      "Validation Loss: 0.3704633414745331\n",
      "Validation Loss: 0.05299147963523865\n",
      "hidden unit: 32\n",
      "Validation Loss: 0.2585243582725525\n",
      "Validation Loss: 0.26189538836479187\n",
      "Validation Loss: 0.3755493760108948\n",
      "Validation Loss: 4.05476713180542\n",
      "Validation Loss: 0.061043620109558105\n",
      "hidden unit: 64\n",
      "Validation Loss: 0.23309703171253204\n",
      "Validation Loss: 0.354391485452652\n",
      "Validation Loss: 0.16308598220348358\n",
      "Validation Loss: 0.06158313900232315\n",
      "Validation Loss: 4.228527545928955\n",
      "hidden unit: 128\n",
      "Validation Loss: 4.023721218109131\n",
      "Validation Loss: 0.15754887461662292\n",
      "Validation Loss: 0.24682755768299103\n",
      "Validation Loss: 0.25807586312294006\n",
      "Validation Loss: 0.3025085926055908\n",
      "Validation Loss: 0.0514424592256546\n",
      "ANN test error: 0.0514424587921267\n",
      "Outer fold 5/5\n",
      "hidden unit: 1\n",
      "Validation Loss: 0.4094441831111908\n",
      "Validation Loss: 0.30632272362709045\n",
      "Validation Loss: 0.6535060405731201\n",
      "Validation Loss: 0.7677791118621826\n",
      "Validation Loss: 4.363193511962891\n",
      "hidden unit: 8\n",
      "Validation Loss: 0.3266366720199585\n",
      "Validation Loss: 0.2704058289527893\n",
      "Validation Loss: 4.364284515380859\n",
      "Validation Loss: 0.22697806358337402\n",
      "Validation Loss: 0.05254990980029106\n",
      "hidden unit: 16\n",
      "Validation Loss: 4.454157829284668\n",
      "Validation Loss: 0.13956837356090546\n",
      "Validation Loss: 0.21219630539417267\n",
      "Validation Loss: 0.12768040597438812\n",
      "Validation Loss: 0.15248332917690277\n",
      "hidden unit: 32\n",
      "Validation Loss: 0.1779329776763916\n",
      "Validation Loss: 0.16362154483795166\n",
      "Validation Loss: 0.12306588143110275\n",
      "Validation Loss: 0.16185614466667175\n",
      "Validation Loss: 4.500707149505615\n",
      "hidden unit: 64\n",
      "Validation Loss: 0.3037615716457367\n",
      "Validation Loss: 4.154607772827148\n",
      "Validation Loss: 0.48012199997901917\n",
      "Validation Loss: 0.08072919398546219\n",
      "Validation Loss: 0.07455047219991684\n",
      "hidden unit: 128\n",
      "Validation Loss: 0.24472613632678986\n",
      "Validation Loss: 0.1952054798603058\n",
      "Validation Loss: 4.092382907867432\n",
      "Validation Loss: 0.2727496027946472\n",
      "Validation Loss: 0.1604834944009781\n",
      "Validation Loss: 0.12134262174367905\n",
      "ANN test error: 0.12134262033428009\n",
      "\n",
      "Mean test errors across outer folds:\n",
      "baseline  : 5.0804 ± 9.8635\n",
      "ridge     : 4.7149 ± 9.1477\n",
      "ann       : 5.1209 ± 9.7438\n"
     ]
    }
   ],
   "source": [
    "# Outer cross-validation loop\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "outer_cv = KFold(K1, shuffle=True)\n",
    "\n",
    "for outer_fold, (outer_train_idx, outer_test_idx) in enumerate(outer_cv.split(X, y)):\n",
    "    print(f\"Outer fold {outer_fold + 1}/{K1}\")\n",
    "\n",
    "    X_train_outer, y_train_outer = X[outer_train_idx], y[outer_train_idx]\n",
    "    X_test_outer, y_test_outer = X[outer_test_idx], y[outer_test_idx]\n",
    "\n",
    "    # Standardize (based on training data)\n",
    "    X_train_mean = np.mean(X_train_outer, axis=0)\n",
    "    X_train_std = np.std(X_train_outer, axis=0)\n",
    "\n",
    "    y_train_mean = np.mean(y_train_outer)\n",
    "    y_train_std = np.std(y_train_outer)\n",
    "\n",
    "    X_train_outer = (X_train_outer - X_train_mean) / X_train_std\n",
    "    X_test_outer = (X_test_outer - X_train_mean) / X_train_std\n",
    "    y_train_outer = (y_train_outer - y_train_mean) / y_train_std\n",
    "    y_test_outer = (y_test_outer - y_train_mean) / y_train_std\n",
    "\n",
    "    # BASELINE MODEL\n",
    "    y_pred_baseline = np.full_like(y_test_outer, np.mean(y_train_outer))\n",
    "    test_errors_outer['baseline'][outer_fold] = np.mean((y_test_outer - y_pred_baseline) ** 2)\n",
    "\n",
    "    #INNER CV for Ridge\n",
    "    inner_cv = KFold(K2, shuffle=True)\n",
    "    ridge_val_errors = np.zeros(len(lambdas))\n",
    "\n",
    "    for i, lam in enumerate(lambdas):\n",
    "        inner_errors = []\n",
    "        for train_idx, val_idx in inner_cv.split(X_train_outer, y_train_outer):\n",
    "            X_train_inner, X_val_inner = X_train_outer[train_idx], X_train_outer[val_idx]\n",
    "            y_train_inner, y_val_inner = y_train_outer[train_idx], y_train_outer[val_idx]\n",
    "\n",
    "            model = Ridge(alpha=lam)\n",
    "            model.fit(X_train_inner, y_train_inner)\n",
    "            y_val_pred = model.predict(X_val_inner)\n",
    "            inner_errors.append(mean_squared_error(y_val_inner, y_val_pred))\n",
    "        ridge_val_errors[i] = np.mean(inner_errors)\n",
    "\n",
    "    optimal_lambda = lambdas[np.argmin(ridge_val_errors)]\n",
    "    optimal_lambdas[outer_fold] = optimal_lambda\n",
    "\n",
    "    # Train Ridge on full outer training set\n",
    "    ridge_model = Ridge(alpha=optimal_lambda)\n",
    "    ridge_model.fit(X_train_outer, y_train_outer)\n",
    "    ridge_test_error = np.mean((y_test_outer - ridge_model.predict(X_test_outer)) ** 2)\n",
    "    test_errors_outer['ridge'][outer_fold] = ridge_test_error\n",
    "    # INNER CV for ANN\n",
    "    ann_val_errors = np.zeros(len(hidden_units))\n",
    "\n",
    "    for j, h in enumerate(hidden_units):\n",
    "        print(f\"hidden unit: {h}\")\n",
    "        inner_errors = []\n",
    "        for train_idx, val_idx in inner_cv.split(X_train_outer, y_train_outer):\n",
    "            X_train_inner, X_val_inner = X_train_outer[train_idx], X_train_outer[val_idx]\n",
    "            y_train_inner, y_val_inner = y_train_outer[train_idx], y_train_outer[val_idx]\n",
    "\n",
    "            val_loss, _ = train_custom_ann(X_train_inner, y_train_inner, X_val_inner, y_val_inner,\n",
    "                                            hidden_units=h, lr=1e-16, epochs=10)\n",
    "            inner_errors.append(val_loss)\n",
    "        ann_val_errors[j] = np.mean(inner_errors)\n",
    "\n",
    "    optimal_h = hidden_units[np.argmin(ann_val_errors)]\n",
    "    optimal_hs[outer_fold] = optimal_h\n",
    "\n",
    "    # Train final ANN model on full outer training set\n",
    "    _, ann_model = train_custom_ann(X_train_outer, y_train_outer, X_test_outer, y_test_outer,\n",
    "                                    hidden_units=optimal_h, lr=1e-16, epochs=10)\n",
    "    ann_model.eval()\n",
    "\n",
    "    device = next(ann_model.parameters()).device  # get model’s device\n",
    "    X_test_t = torch.tensor(X_test_outer, dtype=torch.float32).to(device)\n",
    "    y_test_t = torch.tensor(y_test_outer.reshape(-1, 1), dtype=torch.float32).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred_t = ann_model(X_test_t).cpu().numpy().flatten()\n",
    "\n",
    "    ann_test_error = mean_squared_error(y_test_outer, y_pred_t)\n",
    "    print(f\"ANN test error: {ann_test_error}\")\n",
    "    test_errors_outer['ann'][outer_fold] = ann_test_error\n",
    "\n",
    "\n",
    "# Results summary\n",
    "print(\"\\nMean test errors across outer folds:\")\n",
    "for model_name, errors in test_errors_outer.items():\n",
    "    print(f\"{model_name:10s}: {np.mean(errors):.4f} ± {np.std(errors):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "d8074957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Table 1: Cross-Validation Results =====\n",
      " Fold  lambda* (Ridge)  h* (ANN)  Baseline Test Error  Ridge Test Error  ANN Test Error\n",
      "    1      1644.676178      32.0             0.135353          0.128754        0.154959\n",
      "    2      1534.368409      32.0             0.133316          0.128416        0.282290\n",
      "    3        31.440355      32.0            18.274551         17.452386       21.785370\n",
      "    4      1889.652340     128.0             0.206200          0.187551        0.276659\n",
      "    5      1245.883364      64.0             0.281924          0.262600        0.448001\n",
      "\n",
      "Mean ± Std of Test Errors across folds:\n",
      "baseline  : 3.8063 ± 7.2343\n",
      "ridge     : 3.6319 ± 6.9104\n",
      "ann       : 4.5895 ± 8.5985\n"
     ]
    }
   ],
   "source": [
    "# Summarize Results in Table\n",
    "results_df = pd.DataFrame({\n",
    "    'Fold': np.arange(1, K1 + 1),\n",
    "    'lambda* (Ridge)': optimal_lambdas,\n",
    "    'h* (ANN)': optimal_hs,\n",
    "    'Baseline Test Error': test_errors_outer['baseline'],\n",
    "    'Ridge Test Error': test_errors_outer['ridge'],\n",
    "    'ANN Test Error': test_errors_outer['ann']\n",
    "})\n",
    "\n",
    "# Display the table\n",
    "print(\"\\n===== Table 1: Cross-Validation Results =====\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nMean ± Std of Test Errors across folds:\")\n",
    "for model_name, errors in test_errors_outer.items():\n",
    "    print(f\"{model_name:10s}: {np.mean(errors):.4f} ± {np.std(errors):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cfd076",
   "metadata": {},
   "source": [
    "We ran 2 level cross validation over 3 configurations: A baseline model, calculating the mean ver each outer fold, linear regression, and a neural network. Our table shows that the results across the cross validation folds do not favor a clear approach. Additionally the baseline is only slightly surpassed by the linear regression, and the neural network is performing worse which suggests that a single layer neural network can't capture the training data. It is important to note that this is only based on the cross-validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtucompvis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
