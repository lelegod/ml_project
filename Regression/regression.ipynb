{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f6ef9fd",
   "metadata": {},
   "source": [
    "Our prediction target for the regression is the mass attribute, as we stated it in our previous report. The mass will be predicted based on the following attributes: distance, stellar_magnitude, orbital_radius, orbital_period, eccentricity and radius attributes. This choice is based on our previous analysis and research of the dataset where we found that the mass could potentially have a high importance in predicting the planet type which we predict for our classification task.\n",
    "Sources: \n",
    "- https://www.kaggle.com/code/suhanikulshrestha02/exoplanet-characterization-using-ml\n",
    "- https://www.kaggle.com/code/mikedelong/looking-for-earth-like-planets-with-scatter-plots\n",
    "\n",
    "Additionally, the mass attribute was found to be less correlated with other variables than most other attributes (e.g. orbital period and orbital radius) which makes it a more interesting target for our Neural Network regression.\n",
    "[Correlation Matrix relevant part could be added...]\n",
    "\n",
    "In order to make our data suitable for regression tasks, we needed to do a few transformations. First of all, the mass attribute was stored in 2 separate attributes: mass_wrt, and mass_multiplier. This way the mass was always stored relative to Earth or Jupiter in the original dataset. To unify this, we converted the masses to kg and created a single mass variable. The same process was repeated for the radius_multiplier and radius_wrt attributes.\n",
    "\n",
    "Some attributes were excluded, as their meaning is not clear for such a task: E.g. Even though detection_method is part of our attribute list, it is not aligned with our objective as it is not a planetary characteristic, more of an artifact of the observation and categorization. Because of this reason such variables were considered to be irrelevant for this task.\n",
    "\n",
    "After these preparatory steps we standardized the data. It is important to highlight here that for the regression task both our features and our target variable was standardized. This choice was based on the scale of our mass attribute, which due to being calculated in kg-s, moves around the range of 10^20. This can lead into anomalies during the training (calculations with such numbers could more easily lead into overflows).\n",
    "\n",
    "Another important point is that the training and validation data has been standardized separately. This is to make sure that no information from the validation set leaks into the training set, which could happen if we standardize the whole dataset beforehand. In such scenario the mean and the variance is calculated on the whole dataset too which includes the samples from the validation set. Thus the model would be able to access this information indirectly based on the new scale of the training data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We chose these attributes as they were also the main target of our analysis for the last assignment.\n",
    "\n",
    "For this we will use a basline model to evaluate if our approach is more insightful than simply predicting the mean of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "580ae55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00167c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4765, 13)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"data/cleaned_5250.csv\")\n",
    "missing_values_idx = dataset.isna().any(axis=1)\n",
    "clean_dataset = dataset[~missing_values_idx]\n",
    "clean_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "083e00bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_obeservation = 4000\n",
    "df = clean_dataset.iloc[range(num_obeservation)]\n",
    "full_df = df.copy()\n",
    "df = df.drop(\"name\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27bfdf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle dataset\n",
    "df = df.sample(frac=1, random_state=11).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5495a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      distance  stellar_magnitude   planet_type  discovery_year  \\\n",
      "0       1254.0           12.91800  Neptune-like            2014   \n",
      "1        915.0           13.84700  Neptune-like            2018   \n",
      "2         90.0            7.00000     Gas Giant            2022   \n",
      "3       3366.0           15.94400  Neptune-like            2014   \n",
      "4       9394.0           15.35100  Neptune-like            2016   \n",
      "...        ...                ...           ...             ...   \n",
      "3995    2040.0           13.27000   Super Earth            2014   \n",
      "3996    4358.0           16.01900  Neptune-like            2014   \n",
      "3997     240.0            8.01852     Gas Giant            2004   \n",
      "3998    5519.0           15.40400  Neptune-like            2016   \n",
      "3999    4850.0           14.19600   Super Earth            2016   \n",
      "\n",
      "      orbital_radius  orbital_period  eccentricity detection_method  \\\n",
      "0           0.110000        0.035866          0.00          Transit   \n",
      "1           0.049700        0.012047          0.00          Transit   \n",
      "2          13.125939       47.100000          0.07  Radial Velocity   \n",
      "3           0.104000        0.034771          0.00          Transit   \n",
      "4           0.193900        0.083504          0.00          Transit   \n",
      "...              ...             ...           ...              ...   \n",
      "3995        0.051000        0.010951          0.00          Transit   \n",
      "3996        0.090000        0.026557          0.00          Transit   \n",
      "3997        0.047900        0.009309          0.03  Radial Velocity   \n",
      "3998        0.165400        0.067077          0.00          Transit   \n",
      "3999        0.380000        0.182341          0.00          Transit   \n",
      "\n",
      "              mass     radius  \n",
      "0     3.577228e+25  14471.577  \n",
      "1     5.380772e+25  18386.593  \n",
      "2     1.104693e+28  79698.540  \n",
      "3     3.374180e+25  13982.200  \n",
      "4     3.045720e+25  13457.580  \n",
      "...            ...        ...  \n",
      "3995  1.182456e+25   7781.160  \n",
      "3996  3.069608e+25  13521.360  \n",
      "3997  1.935960e+27  85990.530  \n",
      "3998  7.285840e+25  21952.054  \n",
      "3999  2.484352e+25  11926.860  \n",
      "\n",
      "[4000 rows x 10 columns] (4000, 10)\n"
     ]
    }
   ],
   "source": [
    "# mass transformation: The dataset contains a mass calculation based on two planets. We unify that into a single mass variable\n",
    "jupiter_mass_kg = 1.898 * 10**27 #kg\n",
    "jupiter_radius_km = 69911 #km\n",
    "earth_mass_kg = 5.972 * 10**24\n",
    "earth_radius_km = 6378\n",
    "df[\"mass_wrt\"] = np.where(df[\"mass_wrt\"] == \"Jupiter\", jupiter_mass_kg, earth_mass_kg)\n",
    "df[\"mass\"] = np.multiply(df[\"mass_multiplier\"], df[\"mass_wrt\"])\n",
    "df[\"radius_wrt\"] = np.where(df[\"radius_wrt\"] == \"Jupiter\", jupiter_radius_km, earth_radius_km)\n",
    "df[\"radius\"] = np.multiply(df[\"radius_multiplier\"], df[\"radius_wrt\"])\n",
    "df = df.drop([\"mass_wrt\", \"radius_wrt\", \"mass_multiplier\", \"radius_multiplier\"], axis=1)\n",
    "print(df, df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2259b62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>stellar_magnitude</th>\n",
       "      <th>planet_type</th>\n",
       "      <th>discovery_year</th>\n",
       "      <th>orbital_radius</th>\n",
       "      <th>orbital_period</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>detection_method</th>\n",
       "      <th>mass</th>\n",
       "      <th>radius</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1254.0</td>\n",
       "      <td>12.91800</td>\n",
       "      <td>Neptune-like</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.035866</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Transit</td>\n",
       "      <td>3.577228e+25</td>\n",
       "      <td>14471.577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>915.0</td>\n",
       "      <td>13.84700</td>\n",
       "      <td>Neptune-like</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>0.012047</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Transit</td>\n",
       "      <td>5.380772e+25</td>\n",
       "      <td>18386.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.0</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>Gas Giant</td>\n",
       "      <td>2022</td>\n",
       "      <td>13.125939</td>\n",
       "      <td>47.100000</td>\n",
       "      <td>0.07</td>\n",
       "      <td>Radial Velocity</td>\n",
       "      <td>1.104693e+28</td>\n",
       "      <td>79698.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3366.0</td>\n",
       "      <td>15.94400</td>\n",
       "      <td>Neptune-like</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.034771</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Transit</td>\n",
       "      <td>3.374180e+25</td>\n",
       "      <td>13982.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9394.0</td>\n",
       "      <td>15.35100</td>\n",
       "      <td>Neptune-like</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.193900</td>\n",
       "      <td>0.083504</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Transit</td>\n",
       "      <td>3.045720e+25</td>\n",
       "      <td>13457.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>579.0</td>\n",
       "      <td>13.49900</td>\n",
       "      <td>Terrestrial</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.011225</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Transit</td>\n",
       "      <td>4.473028e+24</td>\n",
       "      <td>5931.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>133.0</td>\n",
       "      <td>6.68804</td>\n",
       "      <td>Gas Giant</td>\n",
       "      <td>2022</td>\n",
       "      <td>3.530000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>0.41</td>\n",
       "      <td>Direct Imaging</td>\n",
       "      <td>2.410460e+28</td>\n",
       "      <td>102070.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>405.0</td>\n",
       "      <td>16.40000</td>\n",
       "      <td>Neptune-like</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>0.059685</td>\n",
       "      <td>0.08</td>\n",
       "      <td>Transit</td>\n",
       "      <td>3.218908e+25</td>\n",
       "      <td>13904.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2875.0</td>\n",
       "      <td>13.25800</td>\n",
       "      <td>Super Earth</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.025188</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Transit</td>\n",
       "      <td>1.319812e+25</td>\n",
       "      <td>8227.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>3072.0</td>\n",
       "      <td>14.13200</td>\n",
       "      <td>Super Earth</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Transit</td>\n",
       "      <td>2.281304e+25</td>\n",
       "      <td>11352.840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     distance  stellar_magnitude   planet_type  discovery_year  \\\n",
       "0      1254.0           12.91800  Neptune-like            2014   \n",
       "1       915.0           13.84700  Neptune-like            2018   \n",
       "2        90.0            7.00000     Gas Giant            2022   \n",
       "3      3366.0           15.94400  Neptune-like            2014   \n",
       "4      9394.0           15.35100  Neptune-like            2016   \n",
       "..        ...                ...           ...             ...   \n",
       "995     579.0           13.49900   Terrestrial            2014   \n",
       "996     133.0            6.68804     Gas Giant            2022   \n",
       "997     405.0           16.40000  Neptune-like            2017   \n",
       "998    2875.0           13.25800   Super Earth            2014   \n",
       "999    3072.0           14.13200   Super Earth            2016   \n",
       "\n",
       "     orbital_radius  orbital_period  eccentricity detection_method  \\\n",
       "0          0.110000        0.035866          0.00          Transit   \n",
       "1          0.049700        0.012047          0.00          Transit   \n",
       "2         13.125939       47.100000          0.07  Radial Velocity   \n",
       "3          0.104000        0.034771          0.00          Transit   \n",
       "4          0.193900        0.083504          0.00          Transit   \n",
       "..              ...             ...           ...              ...   \n",
       "995        0.044000        0.011225          0.00          Transit   \n",
       "996        3.530000        5.700000          0.41   Direct Imaging   \n",
       "997        0.121000        0.059685          0.08          Transit   \n",
       "998        0.091000        0.025188          0.00          Transit   \n",
       "999        0.044400        0.009856          0.00          Transit   \n",
       "\n",
       "             mass      radius  \n",
       "0    3.577228e+25   14471.577  \n",
       "1    5.380772e+25   18386.593  \n",
       "2    1.104693e+28   79698.540  \n",
       "3    3.374180e+25   13982.200  \n",
       "4    3.045720e+25   13457.580  \n",
       "..            ...         ...  \n",
       "995  4.473028e+24    5931.540  \n",
       "996  2.410460e+28  102070.060  \n",
       "997  3.218908e+25   13904.040  \n",
       "998  1.319812e+25    8227.620  \n",
       "999  2.281304e+25   11352.840  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c84544e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance             1.0\n",
      "stellar_magnitude    1.0\n",
      "orbital_radius       1.0\n",
      "orbital_period       1.0\n",
      "eccentricity         1.0\n",
      "mass                 1.0\n",
      "radius               1.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>stellar_magnitude</th>\n",
       "      <th>orbital_radius</th>\n",
       "      <th>orbital_period</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>mass</th>\n",
       "      <th>radius</th>\n",
       "      <th>planet_type</th>\n",
       "      <th>detection_method</th>\n",
       "      <th>discovery_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.353356</td>\n",
       "      <td>0.076206</td>\n",
       "      <td>-0.038587</td>\n",
       "      <td>-0.020460</td>\n",
       "      <td>-0.472049</td>\n",
       "      <td>-0.107968</td>\n",
       "      <td>-0.549389</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.563231</td>\n",
       "      <td>0.369147</td>\n",
       "      <td>-0.039057</td>\n",
       "      <td>-0.020461</td>\n",
       "      <td>-0.472049</td>\n",
       "      <td>-0.107256</td>\n",
       "      <td>-0.425618</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.073990</td>\n",
       "      <td>-1.789910</td>\n",
       "      <td>0.062761</td>\n",
       "      <td>-0.017790</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.326747</td>\n",
       "      <td>1.512709</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.954187</td>\n",
       "      <td>1.030391</td>\n",
       "      <td>-0.038634</td>\n",
       "      <td>-0.020460</td>\n",
       "      <td>-0.472049</td>\n",
       "      <td>-0.108048</td>\n",
       "      <td>-0.564860</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.686132</td>\n",
       "      <td>0.843401</td>\n",
       "      <td>-0.037934</td>\n",
       "      <td>-0.020457</td>\n",
       "      <td>-0.472049</td>\n",
       "      <td>-0.108178</td>\n",
       "      <td>-0.581445</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>0.133258</td>\n",
       "      <td>0.187202</td>\n",
       "      <td>-0.039047</td>\n",
       "      <td>-0.020461</td>\n",
       "      <td>-0.472049</td>\n",
       "      <td>-0.108913</td>\n",
       "      <td>-0.760901</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>1.568336</td>\n",
       "      <td>1.054041</td>\n",
       "      <td>-0.038743</td>\n",
       "      <td>-0.020461</td>\n",
       "      <td>-0.472049</td>\n",
       "      <td>-0.108168</td>\n",
       "      <td>-0.579429</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>-0.981125</td>\n",
       "      <td>-1.468741</td>\n",
       "      <td>-0.039071</td>\n",
       "      <td>-0.020462</td>\n",
       "      <td>-0.269336</td>\n",
       "      <td>-0.032949</td>\n",
       "      <td>1.711625</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>2.287113</td>\n",
       "      <td>0.860114</td>\n",
       "      <td>-0.038156</td>\n",
       "      <td>-0.020458</td>\n",
       "      <td>-0.472049</td>\n",
       "      <td>-0.106504</td>\n",
       "      <td>-0.312899</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>1.872934</td>\n",
       "      <td>0.479196</td>\n",
       "      <td>-0.036485</td>\n",
       "      <td>-0.020452</td>\n",
       "      <td>-0.472049</td>\n",
       "      <td>-0.108399</td>\n",
       "      <td>-0.629838</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      distance  stellar_magnitude  orbital_radius  orbital_period  \\\n",
       "0    -0.353356           0.076206       -0.038587       -0.020460   \n",
       "1    -0.563231           0.369147       -0.039057       -0.020461   \n",
       "2    -1.073990          -1.789910        0.062761       -0.017790   \n",
       "3     0.954187           1.030391       -0.038634       -0.020460   \n",
       "4     4.686132           0.843401       -0.037934       -0.020457   \n",
       "...        ...                ...             ...             ...   \n",
       "3995  0.133258           0.187202       -0.039047       -0.020461   \n",
       "3996  1.568336           1.054041       -0.038743       -0.020461   \n",
       "3997 -0.981125          -1.468741       -0.039071       -0.020462   \n",
       "3998  2.287113           0.860114       -0.038156       -0.020458   \n",
       "3999  1.872934           0.479196       -0.036485       -0.020452   \n",
       "\n",
       "      eccentricity      mass    radius  planet_type  detection_method  \\\n",
       "0        -0.472049 -0.107968 -0.549389            1                 6   \n",
       "1        -0.472049 -0.107256 -0.425618            1                 6   \n",
       "2         0.000947  0.326747  1.512709            0                 5   \n",
       "3        -0.472049 -0.108048 -0.564860            1                 6   \n",
       "4        -0.472049 -0.108178 -0.581445            1                 6   \n",
       "...            ...       ...       ...          ...               ...   \n",
       "3995     -0.472049 -0.108913 -0.760901            2                 6   \n",
       "3996     -0.472049 -0.108168 -0.579429            1                 6   \n",
       "3997     -0.269336 -0.032949  1.711625            0                 5   \n",
       "3998     -0.472049 -0.106504 -0.312899            1                 6   \n",
       "3999     -0.472049 -0.108399 -0.629838            2                 6   \n",
       "\n",
       "      discovery_year  \n",
       "0                 18  \n",
       "1                 22  \n",
       "2                 26  \n",
       "3                 18  \n",
       "4                 20  \n",
       "...              ...  \n",
       "3995              18  \n",
       "3996              18  \n",
       "3997               8  \n",
       "3998              20  \n",
       "3999              20  \n",
       "\n",
       "[4000 rows x 10 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "planet_type = df[\"planet_type\"]\n",
    "encoded_df = df.copy()\n",
    "#we encode the categorical variables, to make it digestable for the training stage later\n",
    "encoded_df[\"detection_method\"] = encoded_df[\"detection_method\"].astype(\"category\").cat.codes\n",
    "encoded_df[\"planet_type\"] = encoded_df[\"planet_type\"].astype(\"category\").cat.codes\n",
    "encoded_df[\"discovery_year\"] = encoded_df[\"discovery_year\"].astype(\"category\").cat.codes\n",
    "\n",
    "#we have a separate df, so that the standardization is only done for the non-categorical variables\n",
    "df_without_type = encoded_df.drop([\"planet_type\", \"detection_method\", \"discovery_year\"] , axis=1)\n",
    "\n",
    "df_std = (df_without_type - np.mean(df_without_type, axis=0)) / np.std(df_without_type, axis=0)\n",
    "print(np.std(df_std, axis=0))\n",
    "\n",
    "#we add back everything\n",
    "df_std[\"planet_type\"] = encoded_df[\"planet_type\"]\n",
    "df_std[\"detection_method\"] = encoded_df[\"detection_method\"]\n",
    "df_std[\"discovery_year\"] = encoded_df[\"discovery_year\"]\n",
    "df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03301f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Gas Giant', 'Neptune-like', 'Super Earth', 'Terrestrial'], dtype='object')\n",
      "Index(['Astrometry', 'Direct Imaging', 'Disk Kinematics',\n",
      "       'Eclipse Timing Variations', 'Orbital Brightness Modulation',\n",
      "       'Radial Velocity', 'Transit', 'Transit Timing Variations'],\n",
      "      dtype='object')\n",
      "Index([1995, 1996, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007,\n",
      "       2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019,\n",
      "       2020, 2021, 2022, 2023],\n",
      "      dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "planet_cats = df[\"planet_type\"].astype(\"category\")\n",
    "print(planet_cats.cat.categories) \n",
    "detection_cats = df[\"detection_method\"].astype(\"category\")\n",
    "print(detection_cats.cat.categories)\n",
    "discovery_cats = df[\"discovery_year\"].astype(\"category\")\n",
    "print(discovery_cats.cat.categories) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b5e32cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 6) (4000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df_without_type.drop(columns=['mass']).values\n",
    "X_columns = df_without_type.drop(columns=['mass']).columns\n",
    "y = df_without_type['mass'].values\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ad4c934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.57722800e+25, 5.38077200e+25, 1.10469294e+28, ...,\n",
       "       1.93596000e+27, 7.28584000e+25, 2.48435200e+25], shape=(4000,))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6772d4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a2d8bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.logspace(-10, 10, 200)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=11)\n",
    "\n",
    "train_errors = []\n",
    "test_errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4700057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # todo polynomial features sklearn\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "# for lam in lambdas:\n",
    "#     ridge = make_pipeline(PolynomialFeatures(degree=3), Ridge(alpha=lam))\n",
    "#     #ridge = Ridge(alpha=lam)\n",
    "#     fold_train_errors = []\n",
    "#     fold_test_errors = []\n",
    "    \n",
    "#     for train_idx, test_idx in kf.split(X):\n",
    "#         X_train, X_test = X[train_idx], X[test_idx]\n",
    "#         y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "#         X_train_mean = np.mean(X_train, axis=0)\n",
    "#         X_train_std = np.std(X_train, axis=0)\n",
    "\n",
    "#         y_train_mean = np.mean(y_train)\n",
    "#         y_train_std = np.std(y_train)\n",
    "\n",
    "#         X_train = (X_train - X_train_mean) / X_train_std\n",
    "#         y_train = (y_train - y_train_mean) / y_train_std\n",
    "\n",
    "#         X_test = (X_test - X_train_mean) / X_train_std\n",
    "#         y_test = (y_test - y_train_mean) / y_train_std\n",
    "        \n",
    "#         ridge.fit(X_train, y_train)\n",
    "        \n",
    "#         y_pred_train = ridge.predict(X_train)\n",
    "#         y_pred_test = ridge.predict(X_test)\n",
    "        \n",
    "#         fold_train_errors.append(mean_squared_error(y_train, y_pred_train))\n",
    "#         fold_test_errors.append(mean_squared_error(y_test, y_pred_test))\n",
    "    \n",
    "#     train_errors.append(np.mean(fold_train_errors))\n",
    "#     test_errors.append(np.mean(fold_test_errors))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a4330223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "for lam in lambdas:\n",
    "    fold_train_errors = []\n",
    "    fold_test_errors = []\n",
    "    \n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Manual scaling of X and y\n",
    "        X_mean = np.mean(X_train, axis=0)\n",
    "        X_std = np.std(X_train, axis=0)\n",
    "        X_train_scaled = (X_train - X_mean) / X_std\n",
    "        X_test_scaled = (X_test - X_mean) / X_std\n",
    "\n",
    "        y_mean = np.mean(y_train)\n",
    "        y_std = np.std(y_train)\n",
    "        y_train_scaled = (y_train - y_mean) / y_std\n",
    "        y_test_scaled = (y_test - y_mean) / y_std\n",
    "\n",
    "        ridge = Ridge(alpha=lam)\n",
    "        ridge.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "\n",
    "        # Predictions\n",
    "        y_pred_train = ridge.predict(X_train_scaled)\n",
    "        y_pred_test = ridge.predict(X_test_scaled)\n",
    "\n",
    "        fold_train_errors.append(mean_squared_error(y_train_scaled, y_pred_train))\n",
    "        fold_test_errors.append(mean_squared_error(y_test_scaled, y_pred_test))\n",
    "\n",
    "    train_errors.append(np.mean(fold_train_errors))\n",
    "    test_errors.append(np.mean(fold_test_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "acaa7d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal lambda = 1162.3225\n",
      "Minimum Cross-Validation error = 3.5151\n"
     ]
    }
   ],
   "source": [
    "#optimal lambda\n",
    "optimal_idx = np.argmin(test_errors)\n",
    "optimal_lambda = lambdas[optimal_idx]\n",
    "optimal_error = test_errors[optimal_idx]\n",
    "\n",
    "print(f\"Optimal lambda = {optimal_lambda:.4f}\")\n",
    "print(f\"Minimum Cross-Validation error = {optimal_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34ef27f",
   "metadata": {},
   "source": [
    "For the calculation of the generalization error K = 10 fold cross-validation was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f04453cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(lambdas, train_errors, marker='o', label='Training error')\n",
    "plt.plot(lambdas, test_errors, marker='s', label='Test error')\n",
    "\n",
    "# Highlight optimal lambda\n",
    "plt.axvline(optimal_lambda, color='red', linestyle='--', label=f'Optimal lambda = {optimal_lambda:.2f}')\n",
    "plt.scatter(optimal_lambda, optimal_error, color='red', s=80, zorder=5)\n",
    "\n",
    "# Labels and legend\n",
    "plt.xlabel('Regularization parameter lambda')\n",
    "plt.ylabel('Mean squared error (on standardized y)')\n",
    "plt.title('Generalization error vs. lambda (10-fold Cross-Validation)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03265403",
   "metadata": {},
   "source": [
    "As visible on the plot the linear regression model fails to capture the test data. There is a visible difference on the test and the training error. This indicates overfitting on the training set, as the model is not able to generalize the knowledge to the test set, this means that the parameters of the model are tuned to the data it was trained on. \n",
    "\n",
    "\n",
    "This is a logical result when we look deeper into the attributes: The mass is not in a linear relationship with the other attributes. As it is also stated in Kepler's laws (which can be used for planet mass estimation if there is a moon or a spacecraft in orbit of the planet): https://en.wikipedia.org/wiki/Kepler%27s_laws_of_planetary_motion the relationship between some of these attributes is already quadratic or third degree, additionally there is no clear equation that would describe the relationships between our input and target attributes.\n",
    "\n",
    "At the same time it is also observable that regularization helps with limiting the generalization error. As we increase lambda, the generalization error drops, then starts increasing while the training error steadily increases as we include higher and higher lambdas. This is a direct consequence of how regularization is applied, as it \"forces\" the weights away from the overfitting solution. However, if the lambda parameter is too high, it prevents the model from capturing the data and the regularization penalty won't enable the model to fit the data.\n",
    "[Formula for regularization]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4d93b76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.01863267,  0.02458558,  0.04345813, -0.0158928 , -0.03242077,\n",
       "         0.29569879]),\n",
       " np.float64(5.187006577390311e-16),\n",
       " 0.8670206540879437,\n",
       " 0.1338348197590374)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(alpha=optimal_lambda)\n",
    "\n",
    "X_train_scaled = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
    "y_train_scaled = (y_train - np.mean(y_train)) / np.std(y_train)\n",
    "\n",
    "X_test_scaled = (X_test - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
    "y_test_scaled = (y_test - np.mean(y_train)) / np.std(y_train)\n",
    "\n",
    "ridge.fit(X_train_scaled, y_train_scaled)\n",
    "coeffs = ridge.coef_\n",
    "intercept = ridge.intercept_\n",
    "\n",
    "y_pred_train = ridge.predict(X_train_scaled)\n",
    "y_pred_test = ridge.predict(X_test_scaled)\n",
    "\n",
    "train_error = mean_squared_error(y_train_scaled, y_pred_train)\n",
    "test_error = mean_squared_error(y_test_scaled, y_pred_test)\n",
    "\n",
    "coeffs, intercept, train_error, test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "21d7ca76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distance</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stellar_magnitude</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orbital_radius</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orbital_period</td>\n",
       "      <td>-0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eccentricity</td>\n",
       "      <td>-0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>radius</td>\n",
       "      <td>0.296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature  Coefficient\n",
       "0           distance        0.019\n",
       "1  stellar_magnitude        0.025\n",
       "2     orbital_radius        0.044\n",
       "3     orbital_period       -0.016\n",
       "4       eccentricity       -0.032\n",
       "5             radius        0.296"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#round coefficients for better visibility\n",
    "coeffs = np.round(coeffs, 3)\n",
    "\n",
    "# create a table from X_Columns and coeffs\n",
    "coeffs_table = pd.DataFrame({'Feature': X_columns, 'Coefficient': coeffs})\n",
    "coeffs_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2e4d58",
   "metadata": {},
   "source": [
    "Linear regression aims to fit a linear combination of the input features to capture the output feature: f(x,w) = w0 +\n",
    "w1x1+· · ·+wMxM.\n",
    "Now we go deeper into our optimal linear model by looking at the coefficients. These show how the individual attributes are weighted in the linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037532ea",
   "metadata": {},
   "source": [
    "As we see the last coefficient is the most significant, which corresponds to the last attribute in our training data. This coefficient is for the radius. This is in line with our previous analysis from the correlation matrix which also showed the strongest correlation between these 2 attributes. The other 5 coefficients are signifcantly smaller which is again in sync with the observations from our data analysis.\n",
    "[correlation matrix comparison]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "76a32428",
   "metadata": {},
   "outputs": [],
   "source": [
    "K1 = 5  # outer folds\n",
    "K2 = 5  # inner folds\n",
    "\n",
    "# Regularization and ANN hyperparameters\n",
    "lambdas = np.logspace(-5, 5, 50)\n",
    "hidden_units = [1, 8, 16, 32, 64, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f78cda2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage\n",
    "test_errors_outer = {\n",
    "    'baseline': np.zeros(K1),\n",
    "    'ridge': np.zeros(K1),\n",
    "    'ann': np.zeros(K1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "61b09aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_hs = np.zeros(K1)\n",
    "optimal_lambdas = np.zeros(K1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "056f689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class PredictorANN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_units):\n",
    "        super(PredictorANN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "fa4a32ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepANN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_units):\n",
    "        super(DeepANN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0faf85ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_custom_ann(X_train, y_train, X_val, y_val, hidden_units, \n",
    "                      lr=1e-3, weight_decay=0.0, epochs=200, batch_size=32, verbose=False):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    X_train_t = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train_t = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32).to(device)\n",
    "    X_val_t = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "    y_val_t = torch.tensor(y_val.reshape(-1, 1), dtype=torch.float32).to(device)\n",
    "\n",
    "    # Datasets and loaders\n",
    "    train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Initialize model, loss, optimizer\n",
    "    model = DeepANN(X_train.shape[1], hidden_units).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_preds = model(X_val_t)\n",
    "        val_loss = criterion(val_preds, y_val_t).item()\n",
    "\n",
    "    print(f'Validation Loss: {val_loss}')\n",
    "    return val_loss, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d1636794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.05212028697133064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.05212028697133064,\n",
       " DeepANN(\n",
       "   (model): Sequential(\n",
       "     (0): Linear(in_features=6, out_features=32, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "     (3): ReLU()\n",
       "     (4): Linear(in_features=32, out_features=32, bias=True)\n",
       "     (5): ReLU()\n",
       "     (6): Linear(in_features=32, out_features=32, bias=True)\n",
       "     (7): ReLU()\n",
       "     (8): Linear(in_features=32, out_features=32, bias=True)\n",
       "     (9): ReLU()\n",
       "     (10): Linear(in_features=32, out_features=1, bias=True)\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_custom_ann(X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled, hidden_units=32, lr=1e-12, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "81315fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer fold 1/5\n",
      "Validation Loss: 4.316874027252197\n",
      "Validation Loss: 1.075278639793396\n",
      "Validation Loss: 0.4249544143676758\n",
      "Validation Loss: 0.10473494976758957\n",
      "Validation Loss: 1.4323627948760986\n",
      "Validation Loss: 0.17198435962200165\n",
      "Validation Loss: 4.337333679199219\n",
      "Validation Loss: 0.11804299801588058\n",
      "Validation Loss: 0.23547320067882538\n",
      "Validation Loss: 0.22315554320812225\n",
      "Validation Loss: 0.1608789712190628\n",
      "Validation Loss: 0.35954880714416504\n",
      "Validation Loss: 4.334338188171387\n",
      "Validation Loss: 0.07239440828561783\n",
      "Validation Loss: 0.19459541141986847\n",
      "Validation Loss: 4.315360069274902\n",
      "Validation Loss: 0.0554991140961647\n",
      "Validation Loss: 0.19625143706798553\n",
      "Validation Loss: 0.19624364376068115\n",
      "Validation Loss: 0.27890869975090027\n",
      "Validation Loss: 0.0568835623562336\n",
      "Validation Loss: 0.16220244765281677\n",
      "Validation Loss: 0.2008003443479538\n",
      "Validation Loss: 0.06083321198821068\n",
      "Validation Loss: 4.519579887390137\n",
      "Validation Loss: 0.0614822693169117\n",
      "Validation Loss: 0.3581054210662842\n",
      "Validation Loss: 4.197028636932373\n",
      "Validation Loss: 0.33526086807250977\n",
      "Validation Loss: 0.057500697672367096\n",
      "Validation Loss: 0.20543399453163147\n",
      "Outer fold 2/5\n",
      "Validation Loss: 4.401438236236572\n",
      "Validation Loss: 0.5038658976554871\n",
      "Validation Loss: 0.4619694650173187\n",
      "Validation Loss: 0.9235383868217468\n",
      "Validation Loss: 0.3839251697063446\n",
      "Validation Loss: 4.270392417907715\n",
      "Validation Loss: 0.08547759801149368\n",
      "Validation Loss: 0.21149729192256927\n",
      "Validation Loss: 0.48254209756851196\n",
      "Validation Loss: 0.3599889278411865\n",
      "Validation Loss: 0.16549526154994965\n",
      "Validation Loss: 0.19537268579006195\n",
      "Validation Loss: 0.058850038796663284\n",
      "Validation Loss: 4.349716663360596\n",
      "Validation Loss: 0.24131357669830322\n",
      "Validation Loss: 4.323231220245361\n",
      "Validation Loss: 0.12008535116910934\n",
      "Validation Loss: 0.3790489137172699\n",
      "Validation Loss: 0.1674594134092331\n",
      "Validation Loss: 0.08191181719303131\n",
      "Validation Loss: 0.15748246014118195\n",
      "Validation Loss: 0.15373699367046356\n",
      "Validation Loss: 0.4176301956176758\n",
      "Validation Loss: 0.0789046511054039\n",
      "Validation Loss: 4.256842613220215\n",
      "Validation Loss: 0.15902939438819885\n",
      "Validation Loss: 0.18974697589874268\n",
      "Validation Loss: 4.179204940795898\n",
      "Validation Loss: 0.32164451479911804\n",
      "Validation Loss: 0.16495050489902496\n",
      "Validation Loss: 0.18900156021118164\n",
      "Outer fold 3/5\n",
      "Validation Loss: 2.358092784881592\n",
      "Validation Loss: 0.8781010508537292\n",
      "Validation Loss: 1.0822490453720093\n",
      "Validation Loss: 1.7058700323104858\n",
      "Validation Loss: 0.6625856757164001\n",
      "Validation Loss: 1.3807562589645386\n",
      "Validation Loss: 0.5744349360466003\n",
      "Validation Loss: 1.6054681539535522\n",
      "Validation Loss: 0.3966277539730072\n",
      "Validation Loss: 1.2617931365966797\n",
      "Validation Loss: 0.43431010842323303\n",
      "Validation Loss: 1.5266717672348022\n",
      "Validation Loss: 1.4702026844024658\n",
      "Validation Loss: 1.2154806852340698\n",
      "Validation Loss: 0.5712611079216003\n",
      "Validation Loss: 0.5214425921440125\n",
      "Validation Loss: 0.35978928208351135\n",
      "Validation Loss: 0.511110246181488\n",
      "Validation Loss: 1.175663709640503\n",
      "Validation Loss: 2.4454991817474365\n",
      "Validation Loss: 1.6609960794448853\n",
      "Validation Loss: 1.116622805595398\n",
      "Validation Loss: 0.4532855153083801\n",
      "Validation Loss: 0.4162910580635071\n",
      "Validation Loss: 1.3537046909332275\n",
      "Validation Loss: 1.7195278406143188\n",
      "Validation Loss: 0.5218087434768677\n",
      "Validation Loss: 0.357021689414978\n",
      "Validation Loss: 2.0836572647094727\n",
      "Validation Loss: 0.3262130916118622\n",
      "Validation Loss: 30.318788528442383\n",
      "Outer fold 4/5\n",
      "Validation Loss: 0.4179946482181549\n",
      "Validation Loss: 4.424266338348389\n",
      "Validation Loss: 0.12952671945095062\n",
      "Validation Loss: 1.0381819009780884\n",
      "Validation Loss: 0.4898087978363037\n",
      "Validation Loss: 0.3426433503627777\n",
      "Validation Loss: 0.06059819087386131\n",
      "Validation Loss: 0.1507030874490738\n",
      "Validation Loss: 4.275574207305908\n",
      "Validation Loss: 0.22179925441741943\n",
      "Validation Loss: 0.1687949001789093\n",
      "Validation Loss: 0.05220801755785942\n",
      "Validation Loss: 0.05931782349944115\n",
      "Validation Loss: 0.14337767660617828\n",
      "Validation Loss: 4.594583511352539\n",
      "Validation Loss: 0.36735257506370544\n",
      "Validation Loss: 4.07832145690918\n",
      "Validation Loss: 0.4344286024570465\n",
      "Validation Loss: 0.05655045434832573\n",
      "Validation Loss: 0.16063208878040314\n",
      "Validation Loss: 0.06227181479334831\n",
      "Validation Loss: 0.19312500953674316\n",
      "Validation Loss: 4.307733058929443\n",
      "Validation Loss: 0.14621946215629578\n",
      "Validation Loss: 0.3088143765926361\n",
      "Validation Loss: 0.05988946184515953\n",
      "Validation Loss: 4.372523784637451\n",
      "Validation Loss: 0.2896342873573303\n",
      "Validation Loss: 0.053255386650562286\n",
      "Validation Loss: 0.23646950721740723\n",
      "Validation Loss: 0.06340385228395462\n",
      "Outer fold 5/5\n",
      "Validation Loss: 1.0440950393676758\n",
      "Validation Loss: 0.4726668894290924\n",
      "Validation Loss: 0.8406279683113098\n",
      "Validation Loss: 5.008683681488037\n",
      "Validation Loss: 0.63112872838974\n",
      "Validation Loss: 0.2653979957103729\n",
      "Validation Loss: 0.4051453173160553\n",
      "Validation Loss: 4.149696350097656\n",
      "Validation Loss: 0.19637861847877502\n",
      "Validation Loss: 0.2831399142742157\n",
      "Validation Loss: 0.04966985061764717\n",
      "Validation Loss: 0.06981294602155685\n",
      "Validation Loss: 0.23100049793720245\n",
      "Validation Loss: 4.38344144821167\n",
      "Validation Loss: 0.31599125266075134\n",
      "Validation Loss: 4.162374496459961\n",
      "Validation Loss: 0.3055330812931061\n",
      "Validation Loss: 0.2593514621257782\n",
      "Validation Loss: 0.08632584661245346\n",
      "Validation Loss: 0.24496129155158997\n",
      "Validation Loss: 0.06580612808465958\n",
      "Validation Loss: 0.060753848403692245\n",
      "Validation Loss: 4.256923675537109\n",
      "Validation Loss: 0.43094226717948914\n",
      "Validation Loss: 0.21629224717617035\n",
      "Validation Loss: 0.2342931032180786\n",
      "Validation Loss: 0.14305460453033447\n",
      "Validation Loss: 4.276119709014893\n",
      "Validation Loss: 0.29743292927742004\n",
      "Validation Loss: 0.041624460369348526\n",
      "Validation Loss: 0.06109930947422981\n",
      "\n",
      "Mean test errors across outer folds:\n",
      "baseline  : 6.1715 ± 12.1002\n",
      "ridge     : 5.7796 ± 11.3051\n",
      "ann       : 6.1675 ± 12.0758\n"
     ]
    }
   ],
   "source": [
    "# Outer cross-validation loop\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "outer_cv = KFold(K1, shuffle=True)\n",
    "\n",
    "for outer_fold, (outer_train_idx, outer_test_idx) in enumerate(outer_cv.split(X, y)):\n",
    "    print(f\"Outer fold {outer_fold + 1}/{K1}\")\n",
    "\n",
    "    X_train_outer, y_train_outer = X[outer_train_idx], y[outer_train_idx]\n",
    "    X_test_outer, y_test_outer = X[outer_test_idx], y[outer_test_idx]\n",
    "\n",
    "    # Standardize (based on training data)\n",
    "    X_train_mean = np.mean(X_train_outer, axis=0)\n",
    "    X_train_std = np.std(X_train_outer, axis=0)\n",
    "\n",
    "    y_train_mean = np.mean(y_train_outer)\n",
    "    y_train_std = np.std(y_train_outer)\n",
    "\n",
    "    X_train_outer = (X_train_outer - X_train_mean) / X_train_std\n",
    "    X_test_outer = (X_test_outer - X_train_mean) / X_train_std\n",
    "    y_train_outer = (y_train_outer - y_train_mean) / y_train_std\n",
    "    y_test_outer = (y_test_outer - y_train_mean) / y_train_std\n",
    "\n",
    "    # BASELINE MODEL\n",
    "    y_pred_baseline = np.full_like(y_test_outer, np.mean(y_train_outer))\n",
    "    test_errors_outer['baseline'][outer_fold] = np.mean((y_test_outer - y_pred_baseline) ** 2)\n",
    "\n",
    "    #INNER CV for Ridge\n",
    "    inner_cv = KFold(K2, shuffle=True)\n",
    "    ridge_val_errors = np.zeros(len(lambdas))\n",
    "\n",
    "    for i, lam in enumerate(lambdas):\n",
    "        inner_errors = []\n",
    "        for train_idx, val_idx in inner_cv.split(X_train_outer, y_train_outer):\n",
    "            X_train_inner, X_val_inner = X_train_outer[train_idx], X_train_outer[val_idx]\n",
    "            y_train_inner, y_val_inner = y_train_outer[train_idx], y_train_outer[val_idx]\n",
    "\n",
    "            model = Ridge(alpha=lam)\n",
    "            model.fit(X_train_inner, y_train_inner)\n",
    "            y_val_pred = model.predict(X_val_inner)\n",
    "            inner_errors.append(mean_squared_error(y_val_inner, y_val_pred))\n",
    "        ridge_val_errors[i] = np.mean(inner_errors)\n",
    "\n",
    "    optimal_lambda = lambdas[np.argmin(ridge_val_errors)]\n",
    "    optimal_lambdas[outer_fold] = optimal_lambda\n",
    "\n",
    "    # Train Ridge on full outer training set\n",
    "    ridge_model = Ridge(alpha=optimal_lambda)\n",
    "    ridge_model.fit(X_train_outer, y_train_outer)\n",
    "    ridge_test_error = np.mean((y_test_outer - ridge_model.predict(X_test_outer)) ** 2)\n",
    "    test_errors_outer['ridge'][outer_fold] = ridge_test_error\n",
    "    # INNER CV for ANN\n",
    "    ann_val_errors = np.zeros(len(hidden_units))\n",
    "\n",
    "    for j, h in enumerate(hidden_units):\n",
    "        inner_errors = []\n",
    "        for train_idx, val_idx in inner_cv.split(X_train_outer, y_train_outer):\n",
    "            X_train_inner, X_val_inner = X_train_outer[train_idx], X_train_outer[val_idx]\n",
    "            y_train_inner, y_val_inner = y_train_outer[train_idx], y_train_outer[val_idx]\n",
    "\n",
    "            val_loss, _ = train_custom_ann(X_train_inner, y_train_inner, X_val_inner, y_val_inner,\n",
    "                                            hidden_units=h, lr=1e-8, epochs=10)\n",
    "            inner_errors.append(val_loss)\n",
    "        ann_val_errors[j] = np.mean(inner_errors)\n",
    "\n",
    "    optimal_h = hidden_units[np.argmin(ann_val_errors)]\n",
    "    optimal_hs[outer_fold] = optimal_h\n",
    "\n",
    "    # Train final ANN model on full outer training set\n",
    "    _, ann_model = train_custom_ann(X_train_outer, y_train_outer, X_test_outer, y_test_outer,\n",
    "                                    hidden_units=optimal_h, lr=1e-8, epochs=10)\n",
    "    ann_model.eval()\n",
    "\n",
    "    device = next(ann_model.parameters()).device  # get model’s device\n",
    "    X_test_t = torch.tensor(X_test_outer, dtype=torch.float32).to(device)\n",
    "    y_test_t = torch.tensor(y_test_outer.reshape(-1, 1), dtype=torch.float32).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred_t = ann_model(X_test_t).cpu().numpy().flatten()\n",
    "\n",
    "    ann_test_error = mean_squared_error(y_test_outer, y_pred_t)\n",
    "    test_errors_outer['ann'][outer_fold] = ann_test_error\n",
    "\n",
    "\n",
    "# Results summary\n",
    "print(\"\\nMean test errors across outer folds:\")\n",
    "for model_name, errors in test_errors_outer.items():\n",
    "    print(f\"{model_name:10s}: {np.mean(errors):.4f} ± {np.std(errors):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d8074957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Table 1: Cross-Validation Results =====\n",
      " Fold  lambda* (Ridge)  h* (ANN)  Baseline Test Error  Ridge Test Error  ANN Test Error\n",
      "    1       568.986603      64.0             0.200060          0.206891        0.205434\n",
      "    2       910.298178      16.0             0.161102          0.165258        0.189002\n",
      "    3         8.286428      64.0            30.371603         28.389604       30.318784\n",
      "    4      1456.348478     128.0             0.063084          0.061275        0.063404\n",
      "    5       910.298178     128.0             0.061560          0.074977        0.061099\n",
      "\n",
      "Mean ± Std of Test Errors across folds:\n",
      "baseline  : 6.1715 ± 12.1002\n",
      "ridge     : 5.7796 ± 11.3051\n",
      "ann       : 6.1675 ± 12.0758\n"
     ]
    }
   ],
   "source": [
    "# Summarize Results in Table\n",
    "results_df = pd.DataFrame({\n",
    "    'Fold': np.arange(1, K1 + 1),\n",
    "    'lambda* (Ridge)': optimal_lambdas,\n",
    "    'h* (ANN)': optimal_hs,\n",
    "    'Baseline Test Error': test_errors_outer['baseline'],\n",
    "    'Ridge Test Error': test_errors_outer['ridge'],\n",
    "    'ANN Test Error': test_errors_outer['ann']\n",
    "})\n",
    "\n",
    "# Display the table\n",
    "print(\"\\n===== Table 1: Cross-Validation Results =====\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nMean ± Std of Test Errors across folds:\")\n",
    "for model_name, errors in test_errors_outer.items():\n",
    "    print(f\"{model_name:10s}: {np.mean(errors):.4f} ± {np.std(errors):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtucompvis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
